#!/usr/bin/env python3
import sys
sys.path.insert(0,"/home/alguero/Work/smodels")
import json
from pyhfInterface import PyhfData
from pyhfInterface import PyhfUpperLimitComputer
from smodels.experiment.databaseObj import Database
from smodels.tools.physicsUnits import pb, fb, GeV

# SUSY-2018-31
# jsoninputs = []
# with open("SUSY-2018-31_likelihoods/RegionA/BkgOnly.json", "r") as f:
    # jsoninputs.append(json.load(f))
# with open("SUSY-2018-31_likelihoods/RegionB/BkgOnly.json", "r") as f:
    # jsoninputs.append(json.load(f))
# with open("SUSY-2018-31_likelihoods/RegionC/BkgOnly.json", "r") as f:
    # jsoninputs.append(json.load(f))

# efficiencies = [0.15404183, 0.6278016 , 0.46972812, 0.0057462 , 0.02926009, 0.01845257, 0.00412215, 0. ]
# xsec = 12.9E-03
# lumi = 139

# SUSY-2018-04
jsoninputs = []
with open("SUSY-2018-04_likelihoods/Region-combined/BkgOnly.json", "r") as f:
    jsoninputs.append(json.load(f))
# with open("SUSY-2018-04_likelihoods/Region-highMass/BkgOnly.json", "r") as f:
    # jsoninputs.append(json.load(f))
# Fetching the efficiencies from the database
dir = "/home/alguero/Work/smodels-database"
d=Database( dir, discard_zeroes = True )
# print(d)
results=d.getExpResults()
massvec = [[280*GeV,200*GeV], [280*GeV,200*GeV]]
effs = []
for e in results:
    # print ( e.globalInfo.id )
    dsets = [ "SRlow", "SRhigh"]
    topo = "TStauStau"
    for ds in dsets:
        eff = e.getEfficiencyFor ( topo, massvec, ds )
        if not eff: continue
        effs.append ( eff )
lumi = 139
# Upper limit calculation
data = PyhfData(effs,
                            lumi,
                            jsoninputs)
ulcomputer = PyhfUpperLimitComputer(data)
result = ulcomputer.ulSigma()
print("sigma95 = ", result)
# with open("bsm.txt", "w") as out:
    # json.dump(ulcomputer.workspaces[0], out, indent=2)
# with open("patch.txt", "w") as p:
    # json.dump(ulcomputer.patches[0], p, indent=2)