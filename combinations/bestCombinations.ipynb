{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3b66d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import smodels modules\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from smodels.tools import runtime\n",
    "# Define your model (list of BSM particles)\n",
    "runtime.modelFile = 'smodels.share.models.mssm'\n",
    "\n",
    "from smodels.theory import decomposer\n",
    "from smodels.tools.physicsUnits import fb, GeV, TeV\n",
    "from smodels.theory.theoryPrediction import theoryPredictionsFor, TheoryPredictionsCombiner\n",
    "from smodels.experiment.databaseObj import Database\n",
    "from smodels.tools import coverage\n",
    "from smodels.tools.smodelsLogging import setLogLevel\n",
    "from smodels.particlesLoader import BSMList\n",
    "from smodels.share.models.SMparticles import SMList\n",
    "from smodels.theory.model import Model\n",
    "import time\n",
    "\n",
    "setLogLevel(\"info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "47d45ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import taco modules\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.expanduser(\"~/taco_code\"))\n",
    "\n",
    "import numpy as np\n",
    "from codes.Full_SR_Ranking.pathfinder.path_finder import PathFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4a018",
   "metadata": {},
   "source": [
    "## Input array of True/False manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a9aaf5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfAna = ['ATLAS-SUSY-2018-05-ewk-eff', 'ATLAS-SUSY-2018-06-eff', 'ATLAS-SUSY-2018-32-eff',\n",
    "             'ATLAS-SUSY-2018-41-eff','ATLAS-SUSY-2019-02-eff','ATLAS-SUSY-2019-08-eff', 'ATLAS-SUSY-2019-09-eff']\n",
    "comb_matrix = np.array([[False,True,True,True,True,True,True],\n",
    "                        [True,False,True,True,True,True,False],\n",
    "                        [True,True,False,True,False,True,True], \n",
    "                        [True,True,True,False,True,True,True],\n",
    "                        [True,True,False,True,False,True,True],\n",
    "                        [True,True,True,True,True,False,True],\n",
    "                        [True,False,True,True,True,True,False]])\n",
    "\n",
    "np.array(~comb_matrix, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc86576",
   "metadata": {},
   "source": [
    "## Finding Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8aeea9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "slhafile = '/Users/sahananarasimha/smodels/ew_7q306a4m.slha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "15316de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in databaseObj.loadBinaryFile() in 505: loading binary db file /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2018-05-ewk-eff/db31.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 512: Loaded database from /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2018-05-ewk-eff/db31.pcl in 0.0 secs.\n",
      "INFO in model.updateParticles() in 393: Loaded 62 BSM particles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ATLAS-SUSY-2018-05-ewk-eff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in databaseObj.loadBinaryFile() in 505: loading binary db file /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2018-06-eff/db31.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 512: Loaded database from /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2018-06-eff/db31.pcl in 0.0 secs.\n",
      "INFO in model.updateParticles() in 393: Loaded 62 BSM particles\n",
      "INFO in databaseObj.loadBinaryFile() in 505: loading binary db file /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2018-32-eff/db31.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 512: Loaded database from /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2018-32-eff/db31.pcl in 0.0 secs.\n",
      "INFO in model.updateParticles() in 393: Loaded 62 BSM particles\n",
      "INFO in databaseObj.loadBinaryFile() in 505: loading binary db file /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2018-41-eff/db31.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 512: Loaded database from /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2018-41-eff/db31.pcl in 0.0 secs.\n",
      "INFO in model.updateParticles() in 393: Loaded 62 BSM particles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ATLAS-SUSY-2018-06-eff\n",
      "\n",
      "  ATLAS-SUSY-2018-32-eff\n",
      "\n",
      " weight = None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in databaseObj.loadBinaryFile() in 505: loading binary db file /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2019-02-eff/db31.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 512: Loaded database from /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2019-02-eff/db31.pcl in 0.0 secs.\n",
      "INFO in model.updateParticles() in 393: Loaded 62 BSM particles\n",
      "INFO in databaseObj.loadBinaryFile() in 505: loading binary db file /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2019-08-eff/db31.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 512: Loaded database from /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2019-08-eff/db31.pcl in 0.0 secs.\n",
      "INFO in model.updateParticles() in 393: Loaded 62 BSM particles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ATLAS-SUSY-2018-41-eff\n",
      "\n",
      " weight = None\n",
      "\n",
      "  ATLAS-SUSY-2019-02-eff\n",
      "\n",
      " weight = None\n",
      "\n",
      "  ATLAS-SUSY-2019-08-eff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO in databaseObj.loadBinaryFile() in 505: loading binary db file /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2019-09-eff/db31.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 512: Loaded database from /Users/sahananarasimha/smodels-database/13TeV/ATLAS/ATLAS-SUSY-2019-09-eff/db31.pcl in 0.0 secs.\n",
      "INFO in model.updateParticles() in 393: Loaded 62 BSM particles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  ATLAS-SUSY-2019-09-eff\n"
     ]
    }
   ],
   "source": [
    "def getWeightsFor(analyses, inputfile, expected=True):\n",
    "    \n",
    "    sigmacut = 0.005*fb\n",
    "    mingap = 5.*GeV\n",
    "\n",
    "    database = Database('/Users/sahananarasimha/smodels-database/13TeV/ATLAS/%s'%analyses)\n",
    "    \n",
    "    model = Model(BSMparticles = BSMList, SMparticles = SMList)\n",
    "    model.updateParticles(inputFile = slhafile)\n",
    "    \n",
    "    toplist = decomposer.decompose(model, sigmacut, doCompress=True, doInvisible=True, minmassgap=mingap)\n",
    "    print(\"\\n \", analyses)\n",
    "    exp = database.getExpResults()[0]\n",
    "    \n",
    "    predictions = theoryPredictionsFor(exp, toplist, combinedResults=True)\n",
    "    \n",
    "    if not predictions:\n",
    "        print(\"\\n weight =\", predictions)\n",
    "        return None  \n",
    "    \n",
    "    for theoryPrediction in predictions:\n",
    "        dataset = theoryPrediction.dataset\n",
    "\n",
    "        if dataset.getType() == 'combined' or dataset.getType() == 'efficiencyMap':\n",
    "            #get expected llhd\n",
    "            if expected:\n",
    "                #print('\\n', datasetID, txnames, '\\n')\n",
    "                lbsm = theoryPrediction.likelihood(expected=True)\n",
    "                lsm = theoryPrediction.lsm(expected=True)\n",
    "                weight = -np.log(lbsm/lsm)  #returning nll ratio\n",
    "                return weight\n",
    "            \n",
    "            #get observed llhd\n",
    "            lbsm = theoryPrediction.likelihood()\n",
    "            lsm = theoryPrediction.lsm()\n",
    "            weight = -np.log(lbsm/lsm)  #returning nll ratio\n",
    "            return weight\n",
    "                \n",
    "\n",
    "ana_weights = []\n",
    "index = []\n",
    "\n",
    "for ana in listOfAna:\n",
    "    weight = getWeightsFor(analyses = ana, inputfile = slhafile)\n",
    "    \n",
    "    #Get index of analyses for which theoryPrediction is None\n",
    "    if weight == None:\n",
    "        index.append(listOfAna.index(ana))\n",
    "        continue\n",
    "        \n",
    "    ana_weights.append(weight)\n",
    "\n",
    "#Remove analysis from comb_matrix for which theoryPrediction is None\n",
    "comb_matrix = np.delete(np.delete(comb_matrix, index,0), index,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "86a66e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00059875 0.00022952 0.10893801 0.00260334]\n",
      "[[False  True  True  True]\n",
      " [ True False  True False]\n",
      " [ True  True False  True]\n",
      " [ True False  True False]]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(ana_weights))\n",
    "print(comb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cfca7031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'path': [0, 2, 3], 'weight': 0.11214009746215936}, 1: {'path': [2, 3], 'weight': 0.11154134570426773}, 2: {'path': [0, 1, 2], 'weight': 0.10976628453054806}, 3: {'path': [0, 2], 'weight': 0.10953676221863873}, 4: {'path': [1, 2], 'weight': 0.10916753277265642}, 5: {'path': [2], 'weight': 0.1089380104607471}}\n"
     ]
    }
   ],
   "source": [
    "pf = PathFinder(np.array(~comb_matrix, dtype=int), weights=np.array(ana_weights), ignore_subset=True)\n",
    "print(pf.find_path(top=6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1002f",
   "metadata": {},
   "source": [
    "### Though the paper mentions that the weights are log(L_bsm/L_sm), the weights do not get registered if they are negative i..e if L_bsm < L_sm. Hence, I have taken weights to be nll ratio. Should clarify it with Jamie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d090e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143be625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
