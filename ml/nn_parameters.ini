#Database address
[pathing]
databasePath = ../../smodels-database ;Give path to the database "text" directory or to the binary database file -LLP
smodelsPath  = ../../smodels
utilsPath    = ../../smodels-utils
outputPath   = database ;Directory of neural network database for finished models and their analyses, performances, loss plots and logs. If left blank, default database folder will be chosen

#Select database analyses
[database]
analysis = ATLAS-SUSY-2016-32 ;Select single analysis for training CMS-SUS-19-006
txName = THSCPM1b ;Select topologies you want to train, eg: 'T2tt' or 'T2tt,T6WW,..' or 'all'  
dataselector = efficiencyMap ;upperLimit ;efficiencyMap ;Select upperLimit or efficiencyMap results
signalRegion = SR1FULL_175 ;Select SR if dataselector == efficiencyMap SR1FULL_825
overwrite = always ;Check whether you want to override an existing NN with new results. Options include: always, never, outperforming


#General dataset options
[dataset]
samplesize = 1 ;Size of total training data
sampleSplit = 0.8,0.1,0.1 ;Set the ratio our sample data will be split into training, testing and validation sets
loadFile = maps_jan/sample_updated/THSCPM1b_eff_mutrig.dat ;HSCP_ATLAS_1902_01636_eff_maps_Oct5_sfgrid/THSCPM8_eff_mutrig.dat ;Load custom generated dataset. Requires full relative path. Ignores samplesize and instead splits the whole file into traning, testing and validation sets.
massColumns = 0,0,-2,-2,7 ; 1,0,1,0,-3,-3,8 ;Mass columns of loaded file. Use SmodelS type input in form of [b1_mass0,b1_mass1,b1_mass2,b2_mass0,b2_mass1,b2_mass2,b1_width,b2_width,eff/ul], NEGATIVE INDICES MEAN WIDTHS AND WILL BE RESCALED TO LOG(1+w) - M5 [2,1,0,2,1,0,-4,-4,9] - M8 [1,0,1,0,-3,-3,8]
refXsecFile = ../slha/xsecsquark13.txt ;reference xsec file vom utils/slha folder. (optional). Used to calculate a limit of [lumi * refXsec(m0) * eff > 0.01] where all efficiencies will be set to zero. Useful for sparing the NN the need of learning unneccessarily small effs.
refXsecColumns = 0,2 ;columns of masses and xsecs of refXsec file


#Computation device options
[computation]
device = cpu ;Specify which device to be used for computing, 'cpu' for CPU, int 'n' for gpu:'n', default = cpu 
cores = 6
#whichNN = both ;Learn 'regression' (prediction of ULs), 'classification' (shape of convex hull) or 'both'


#Hyper-parameters for regression networks
[regression]
optimizer = Adam
lossFunction = MSErel
learnRate = 1e-4 ;1e-3 seems best for MSErel
batchSize = 16 ; 16
epochNum = 60 ; 80
shape = trap ;Specify shape/architecture of NN (more detailed explanation coming)
activationFunction = prel ;Set activation functions used in hidden layers   LLP note: sel ~80% err, prel ~40%, rel ~30%
layer = 8 ;Set # of hidden layers
nodes = 512 ; 256 ;Set maximum nodes in largest hidden layer
rescaleMethod = standardScore


#Hyper-parameters for classification networks
[classification]
optimizer = Adam
lossFunction = BCE
learnRate = 1e-3
batchSize = 16
epochNum = 1
shape = lin ;Specify shape/architecture of NN (more detailed explanation coming) lin?
activationFunction = prel ;Set activation functions used in hidden layers. Options: rel, prel, sel, lrel
layer = 3 ;Set # of hidden layers
nodes = 256 ;Set maximum nodes in largest hidden layer


#Plots and analysis
[validation]
logFile = true ; create log file of losses and parameters of all models for each topology
lossPlot = true ; create loss plot of final models
runPerformance = false ;run getPerformance.py on final models after search has been completed
